## Project Overview  
This project focuses on multimodal sentiment analysis, incorporating speech, audio, and video data to detect emotions in spoken language. Using the Interactive Emotional Dyadic Motion Capture (IEMOCAP) dataset, our goal is to develop a robust model that can accurately classify emotions from multimodal inputs.
## Features 
Multimodal Data Processing: Integrates speech, audio, and video data for comprehensive emotion analysis. 

Emotion Detection: Classifies emotions into predefined categories (e.g., happiness, sadness, anger, neutral). 

State-of-the-Art Techniques: Utilizes advanced machine learning and deep learning techniques for sentiment analysis. 

IEMOCAP Dataset: Leverages the IEMOCAP dataset, which contains diverse emotional expressions for model training and evaluation. 

### Dataset Link: 
https://www.kaggle.com/datasets/dejolilandry/iemocapfullrelease
